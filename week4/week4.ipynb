{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 4 - Query Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/.kaggle/datasets/week4\n"
     ]
    }
   ],
   "source": [
    "%mkdir -p /workspace/datasets/week4\n",
    "%cd /workspace/datasets/week4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "To preprocess query text, we run the following transformations:\n",
    "- lowercase\n",
    "- remove punctuation\n",
    "- tokenize\n",
    "- stem using porter stemmer \n",
    "\n",
    "As preprocssing text is slow, we do it in a separate step before running other experiments.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ python /workspace/search_with_machine_learning_course/week4/preprocess_queries.py\n",
      "Reading query data from /workspace/datasets/train.csv\n",
      "Preprocessing query data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1865269/1865269 [02:48<00:00, 11079.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   category  ...                          query\n",
      "0              abcat0101001  ...  television panason 50 pulgada\n",
      "1              abcat0101001  ...                          sharp\n",
      "2        pcmcat193100050014  ...                           nook\n",
      "3              abcat0101001  ...                            rca\n",
      "4              abcat0101005  ...                            rca\n",
      "...                     ...  ...                            ...\n",
      "1865264  pcmcat247400050000  ...                            ttv\n",
      "1865265  pcmcat218000050000  ...                          incas\n",
      "1865266  pcmcat248500050020  ...                        ds game\n",
      "1865267  pcmcat209000050008  ...                          archo\n",
      "1865268  pcmcat182300050008  ...                   graphic card\n",
      "\n",
      "[1865269 rows x 3 columns]\n",
      "Saving preprocessed query data to /workspace/datasets/week4/query_df.pk\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args='python /workspace/search_with_machine_learning_course/week4/preprocess_queries.py', returncode=0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmd = f\"python /workspace/search_with_machine_learning_course/week4/preprocess_queries.py\"\n",
    "print(f\"+ {cmd}\")\n",
    "subprocess.run(cmd, shell=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training data for min_queries = 100\n",
    "\n",
    "This will generate `train.mq100.txt` and `test.mq100.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ python /workspace/search_with_machine_learning_course/week4/create_labeled_queries.py --min_queries 100\n",
      "df: len=1854998 columns=['category', 'raw_query', 'query']\n",
      "             category                            raw_query                          query\n",
      "0        abcat0101001  Televisiones Panasonic  50 pulgadas  television panason 50 pulgada\n",
      "1        abcat0101001                                Sharp                          sharp\n",
      "2  pcmcat193100050014                                 nook                           nook\n",
      "3        abcat0101001                                  rca                            rca\n",
      "4        abcat0101005                                  rca                            rca\n",
      "\n",
      "No. of unique categories = 1486\n",
      "No. of categories with #queries < 100 = 630 (leaf) / 668 (all)\n",
      "No. of affected rows = 18336\n",
      "\n",
      "No. of unique categories = 994\n",
      "No. of categories with #queries < 100 = 105 (leaf) / 126 (all)\n",
      "No. of affected rows = 4569\n",
      "\n",
      "No. of unique categories = 920\n",
      "No. of categories with #queries < 100 = 32 (leaf) / 34 (all)\n",
      "No. of affected rows = 1281\n",
      "\n",
      "No. of unique categories = 893\n",
      "No. of categories with #queries < 100 = 5 (leaf) / 5 (all)\n",
      "No. of affected rows = 150\n",
      "\n",
      "No. of unique categories = 890\n",
      "No. of categories with #queries < 100 = 2 (leaf) / 2 (all)\n",
      "No. of affected rows = 12\n",
      "\n",
      "No. of unique categories = 889\n",
      "No. of categories with #queries < 100 = 1 (leaf) / 1 (all)\n",
      "No. of affected rows = 10\n",
      "\n",
      "No. of unique categories = 888\n",
      "No. of categories with #queries < 100 = 0 (leaf) / 0 (all)\n",
      "\n",
      "Writing 1854572 lines to /workspace/datasets/week4/labeled_data.mq100.txt\n",
      "Writing 50000 lines to /workspace/datasets/week4/train.mq100.txt\n",
      "Writing 50000 lines to /workspace/datasets/week4/test.mq100.txt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args='python /workspace/search_with_machine_learning_course/week4/create_labeled_queries.py --min_queries 100', returncode=0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmd = f\"python /workspace/search_with_machine_learning_course/week4/create_labeled_queries.py --min_queries 100\"\n",
    "print(f\"+ {cmd}\")\n",
    "subprocess.run(cmd, shell=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training data for min_queries = 1000\n",
    "\n",
    "This will generate `train.mq1000.txt` and `test.mq1000.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ python /workspace/search_with_machine_learning_course/week4/create_labeled_queries.py --min_queries 1000\n",
      "df: len=1854998 columns=['category', 'raw_query', 'query']\n",
      "             category                            raw_query                          query\n",
      "0        abcat0101001  Televisiones Panasonic  50 pulgadas  television panason 50 pulgada\n",
      "1        abcat0101001                                Sharp                          sharp\n",
      "2  pcmcat193100050014                                 nook                           nook\n",
      "3        abcat0101001                                  rca                            rca\n",
      "4        abcat0101005                                  rca                            rca\n",
      "\n",
      "No. of unique categories = 1486\n",
      "No. of categories with #queries < 1000 = 1099 (leaf) / 1188 (all)\n",
      "No. of affected rows = 207932\n",
      "\n",
      "No. of unique categories = 589\n",
      "No. of categories with #queries < 1000 = 179 (leaf) / 217 (all)\n",
      "No. of affected rows = 66294\n",
      "\n",
      "No. of unique categories = 442\n",
      "No. of categories with #queries < 1000 = 36 (leaf) / 40 (all)\n",
      "No. of affected rows = 14448\n",
      "\n",
      "No. of unique categories = 409\n",
      "No. of categories with #queries < 1000 = 5 (leaf) / 5 (all)\n",
      "No. of affected rows = 2662\n",
      "\n",
      "No. of unique categories = 405\n",
      "No. of categories with #queries < 1000 = 1 (leaf) / 1 (all)\n",
      "No. of affected rows = 364\n",
      "\n",
      "No. of unique categories = 404\n",
      "No. of categories with #queries < 1000 = 0 (leaf) / 0 (all)\n",
      "\n",
      "Writing 1852754 lines to /workspace/datasets/week4/labeled_data.mq1000.txt\n",
      "Writing 50000 lines to /workspace/datasets/week4/train.mq1000.txt\n",
      "Writing 50000 lines to /workspace/datasets/week4/test.mq1000.txt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args='python /workspace/search_with_machine_learning_course/week4/create_labeled_queries.py --min_queries 1000', returncode=0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmd = f\"python /workspace/search_with_machine_learning_course/week4/create_labeled_queries.py --min_queries 1000\"\n",
    "print(f\"+ {cmd}\")\n",
    "subprocess.run(cmd, shell=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_exp(epoch=5, lr=.1, wordNgrams=1):\n",
    "    for mq in [\"100\", \"1000\"]:\n",
    "        model = f\"model.mq{mq}.e{epoch}.lr{lr}.ng{wordNgrams}\"\n",
    "        cmd = f\"fasttext supervised -input train.mq{mq}.txt -output {model} -epoch {epoch} -lr {lr} -wordNgrams {wordNgrams} -seed 42\"\n",
    "        print(\"+\", cmd)\n",
    "        subprocess.run(cmd, shell=True)\n",
    "        subprocess.run(f\"fasttext test {model}.bin test.mq{mq}.txt\", shell=True)\n",
    "        subprocess.run(f\"fasttext test {model}.bin test.mq{mq}.txt 3\", shell=True)\n",
    "        subprocess.run(f\"fasttext test {model}.bin test.mq{mq}.txt 5\", shell=True)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Default fasttext parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ fasttext supervised -input train.mq100.txt -output model.mq100.e5.lr0.1.ng1 -epoch 5 -lr 0.1 -wordNgrams 1 -seed 42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read 0M words\n",
      "Number of words:  7726\n",
      "Number of labels: 884\n",
      "Progress: 100.0% words/sec/thread:    7204 lr:  0.000000 avg.loss:  5.318608 ETA:   0h 0m 0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N\t49991\n",
      "P@1\t0.467\n",
      "R@1\t0.467\n",
      "N\t49991\n",
      "P@3\t0.206\n",
      "R@3\t0.619\n",
      "N\t49991\n",
      "P@5\t0.136\n",
      "R@5\t0.678\n",
      "\n",
      "+ fasttext supervised -input train.mq1000.txt -output model.mq1000.e5.lr0.1.ng1 -epoch 5 -lr 0.1 -wordNgrams 1 -seed 42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read 0M words\n",
      "Number of words:  7773\n",
      "Number of labels: 403\n",
      "Progress: 100.0% words/sec/thread:   15052 lr:  0.000000 avg.loss:  4.360879 ETA:   0h 0m 0s-0.000005 avg.loss:  4.360879 ETA:   0h 0m 0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N\t50000\n",
      "P@1\t0.472\n",
      "R@1\t0.472\n",
      "N\t50000\n",
      "P@3\t0.212\n",
      "R@3\t0.636\n",
      "N\t50000\n",
      "P@5\t0.14\n",
      "R@5\t0.7\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_exp()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Increasing learning rate\n",
    "\n",
    "Increasing learning rate improves precision and recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ fasttext supervised -input train.mq100.txt -output model.mq100.e5.lr0.5.ng1 -epoch 5 -lr 0.5 -wordNgrams 1 -seed 42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read 0M words\n",
      "Number of words:  7726\n",
      "Number of labels: 884\n",
      "Progress: 100.0% words/sec/thread:    7190 lr:  0.000000 avg.loss:  3.861906 ETA:   0h 0m 0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N\t49991\n",
      "P@1\t0.517\n",
      "R@1\t0.517\n",
      "N\t49991\n",
      "P@3\t0.232\n",
      "R@3\t0.697\n",
      "N\t49991\n",
      "P@5\t0.152\n",
      "R@5\t0.761\n",
      "\n",
      "+ fasttext supervised -input train.mq1000.txt -output model.mq1000.e5.lr0.5.ng1 -epoch 5 -lr 0.5 -wordNgrams 1 -seed 42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read 0M words\n",
      "Number of words:  7773\n",
      "Number of labels: 403\n",
      "Progress: 100.0% words/sec/thread:   15343 lr:  0.000000 avg.loss:  3.649434 ETA:   0h 0m 0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N\t50000\n",
      "P@1\t0.524\n",
      "R@1\t0.524\n",
      "N\t50000\n",
      "P@3\t0.235\n",
      "R@3\t0.705\n",
      "N\t50000\n",
      "P@5\t0.153\n",
      "R@5\t0.766\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_exp(lr=.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Increasing epochs\n",
    "\n",
    "Similar improvement as with increased learning rate. Perhaps default parameters result in underfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ fasttext supervised -input train.mq100.txt -output model.mq100.e25.lr0.1.ng1 -epoch 25 -lr 0.1 -wordNgrams 1 -seed 42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read 0M words\n",
      "Number of words:  7726\n",
      "Number of labels: 884\n",
      "Progress: 100.0% words/sec/thread:    7176 lr:  0.000000 avg.loss:  2.710290 ETA:   0h 0m 0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N\t49991\n",
      "P@1\t0.518\n",
      "R@1\t0.518\n",
      "N\t49991\n",
      "P@3\t0.233\n",
      "R@3\t0.699\n",
      "N\t49991\n",
      "P@5\t0.152\n",
      "R@5\t0.761\n",
      "\n",
      "+ fasttext supervised -input train.mq1000.txt -output model.mq1000.e25.lr0.1.ng1 -epoch 25 -lr 0.1 -wordNgrams 1 -seed 42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read 0M words\n",
      "Number of words:  7773\n",
      "Number of labels: 403\n",
      "Progress: 100.0% words/sec/thread:   15339 lr:  0.000000 avg.loss:  2.299196 ETA:   0h 0m 0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N\t50000\n",
      "P@1\t0.522\n",
      "R@1\t0.522\n",
      "N\t50000\n",
      "P@3\t0.234\n",
      "R@3\t0.702\n",
      "N\t50000\n",
      "P@5\t0.153\n",
      "R@5\t0.765\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_exp(epoch=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Increasing both epochs and learning rate\n",
    "\n",
    "Increasing both doesn't really change much."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ fasttext supervised -input train.mq100.txt -output model.mq100.e25.lr0.5.ng1 -epoch 25 -lr 0.5 -wordNgrams 1 -seed 42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read 0M words\n",
      "Number of words:  7726\n",
      "Number of labels: 884\n",
      "Progress: 100.0% words/sec/thread:    7214 lr:  0.000000 avg.loss:  3.373950 ETA:   0h 0m 0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N\t49991\n",
      "P@1\t0.515\n",
      "R@1\t0.515\n",
      "N\t49991\n",
      "P@3\t0.231\n",
      "R@3\t0.693\n",
      "N\t49991\n",
      "P@5\t0.151\n",
      "R@5\t0.757\n",
      "\n",
      "+ fasttext supervised -input train.mq1000.txt -output model.mq1000.e25.lr0.5.ng1 -epoch 25 -lr 0.5 -wordNgrams 1 -seed 42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read 0M words\n",
      "Number of words:  7773\n",
      "Number of labels: 403\n",
      "Progress: 100.0% words/sec/thread:   15228 lr:  0.000000 avg.loss:  3.306704 ETA:   0h 0m 0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N\t50000\n",
      "P@1\t0.516\n",
      "R@1\t0.516\n",
      "N\t50000\n",
      "P@3\t0.232\n",
      "R@3\t0.695\n",
      "N\t50000\n",
      "P@5\t0.152\n",
      "R@5\t0.759\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_exp(epoch=25, lr=.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ fasttext supervised -input train.mq100.txt -output model.mq100.e5.lr0.5.ng2 -epoch 5 -lr 0.5 -wordNgrams 2 -seed 42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read 0M words\n",
      "Number of words:  7726\n",
      "Number of labels: 884\n",
      "Progress: 100.0% words/sec/thread:    7199 lr:  0.000000 avg.loss:  3.755955 ETA:   0h 0m 0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N\t49991\n",
      "P@1\t0.518\n",
      "R@1\t0.518\n",
      "N\t49991\n",
      "P@3\t0.233\n",
      "R@3\t0.698\n",
      "N\t49991\n",
      "P@5\t0.152\n",
      "R@5\t0.762\n",
      "\n",
      "+ fasttext supervised -input train.mq1000.txt -output model.mq1000.e5.lr0.5.ng2 -epoch 5 -lr 0.5 -wordNgrams 2 -seed 42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read 0M words\n",
      "Number of words:  7773\n",
      "Number of labels: 403\n",
      "Progress: 100.0% words/sec/thread:   15226 lr:  0.000000 avg.loss:  3.079125 ETA:   0h 0m 0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N\t50000\n",
      "P@1\t0.522\n",
      "R@1\t0.522\n",
      "N\t50000\n",
      "P@3\t0.235\n",
      "R@3\t0.705\n",
      "N\t50000\n",
      "P@5\t0.154\n",
      "R@5\t0.769\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_exp(lr=.5, wordNgrams=2)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "17f19b2e755769a5519b38b6367878bc0c8e8eee85e91277104d2410a6f820df"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('py39')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
