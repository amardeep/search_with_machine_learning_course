{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 4 - Query Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/.kaggle/datasets/week4\n"
     ]
    }
   ],
   "source": [
    "%mkdir -p /workspace/datasets/week4\n",
    "%cd /workspace/datasets/week4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "To preprocess query text, we run the following transformations:\n",
    "- lowercase\n",
    "- remove punctuation\n",
    "- tokenize\n",
    "- stem using porter stemmer \n",
    "\n",
    "As preprocssing text is slow, we do it in a separate step before running other experiments.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ python /workspace/search_with_machine_learning_course/week4/preprocess_queries.py\n",
      "Reading query data from /workspace/datasets/train.csv\n",
      "Preprocessing query data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1865269/1865269 [02:46<00:00, 11225.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   category  ...                          query\n",
      "0              abcat0101001  ...  television panason 50 pulgada\n",
      "1              abcat0101001  ...                          sharp\n",
      "2        pcmcat193100050014  ...                           nook\n",
      "3              abcat0101001  ...                            rca\n",
      "4              abcat0101005  ...                            rca\n",
      "...                     ...  ...                            ...\n",
      "1865264  pcmcat247400050000  ...                            ttv\n",
      "1865265  pcmcat218000050000  ...                          incas\n",
      "1865266  pcmcat248500050020  ...                        ds game\n",
      "1865267  pcmcat209000050008  ...                          archo\n",
      "1865268  pcmcat182300050008  ...                   graphic card\n",
      "\n",
      "[1865269 rows x 3 columns]\n",
      "Saving preprocessed query data to /workspace/datasets/week4/query_df.pk\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args='python /workspace/search_with_machine_learning_course/week4/preprocess_queries.py', returncode=0)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmd = f\"python /workspace/search_with_machine_learning_course/week4/preprocess_queries.py\"\n",
    "print(f\"+ {cmd}\")\n",
    "subprocess.run(cmd, shell=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training data for min_queries = 100\n",
    "\n",
    "This will generate `train.mq100.txt` and `test.mq100.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ python /workspace/search_with_machine_learning_course/week4/create_labeled_queries.py --min_queries 100\n",
      "df: len=1854998 columns=['category', 'raw_query', 'query']\n",
      "             category                            raw_query                          query\n",
      "0        abcat0101001  Televisiones Panasonic  50 pulgadas  television panason 50 pulgada\n",
      "1        abcat0101001                                Sharp                          sharp\n",
      "2  pcmcat193100050014                                 nook                           nook\n",
      "3        abcat0101001                                  rca                            rca\n",
      "4        abcat0101005                                  rca                            rca\n",
      "\n",
      "No. of unique categories = 1486\n",
      "No. of categories with #queries < 100 = 668\n",
      "No. of affected rows = 19256\n",
      "\n",
      "No. of unique categories = 1004\n",
      "No. of categories with #queries < 100 = 140\n",
      "No. of affected rows = 5858\n",
      "\n",
      "No. of unique categories = 916\n",
      "No. of categories with #queries < 100 = 36\n",
      "No. of affected rows = 1098\n",
      "\n",
      "No. of unique categories = 885\n",
      "No. of categories with #queries < 100 = 5\n",
      "No. of affected rows = 118\n",
      "\n",
      "No. of unique categories = 882\n",
      "No. of categories with #queries < 100 = 2\n",
      "No. of affected rows = 12\n",
      "\n",
      "No. of unique categories = 881\n",
      "No. of categories with #queries < 100 = 1\n",
      "No. of affected rows = 10\n",
      "\n",
      "No. of unique categories = 880\n",
      "No. of categories with #queries < 100 = 0\n",
      "\n",
      "Writing 1854452 lines to /workspace/datasets/week4/labeled_data.mq100.txt\n",
      "Writing 50000 lines to /workspace/datasets/week4/train.mq100.txt\n",
      "Writing 50000 lines to /workspace/datasets/week4/test.mq100.txt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args='python /workspace/search_with_machine_learning_course/week4/create_labeled_queries.py --min_queries 100', returncode=0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmd = f\"python /workspace/search_with_machine_learning_course/week4/create_labeled_queries.py --min_queries 100\"\n",
    "print(f\"+ {cmd}\")\n",
    "subprocess.run(cmd, shell=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training data for min_queries = 1000\n",
    "\n",
    "This will generate `train.mq1000.txt` and `test.mq1000.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ python /workspace/search_with_machine_learning_course/week4/create_labeled_queries.py --min_queries 1000\n",
      "df: len=1854998 columns=['category', 'raw_query', 'query']\n",
      "             category                            raw_query                          query\n",
      "0        abcat0101001  Televisiones Panasonic  50 pulgadas  television panason 50 pulgada\n",
      "1        abcat0101001                                Sharp                          sharp\n",
      "2  pcmcat193100050014                                 nook                           nook\n",
      "3        abcat0101001                                  rca                            rca\n",
      "4        abcat0101005                                  rca                            rca\n",
      "\n",
      "No. of unique categories = 1486\n",
      "No. of categories with #queries < 1000 = 1188\n",
      "No. of affected rows = 224005\n",
      "\n",
      "No. of unique categories = 605\n",
      "No. of categories with #queries < 1000 = 236\n",
      "No. of affected rows = 82358\n",
      "\n",
      "No. of unique categories = 435\n",
      "No. of categories with #queries < 1000 = 48\n",
      "No. of affected rows = 16162\n",
      "\n",
      "No. of unique categories = 394\n",
      "No. of categories with #queries < 1000 = 6\n",
      "No. of affected rows = 2555\n",
      "\n",
      "No. of unique categories = 389\n",
      "No. of categories with #queries < 1000 = 1\n",
      "No. of affected rows = 364\n",
      "\n",
      "No. of unique categories = 388\n",
      "No. of categories with #queries < 1000 = 0\n",
      "\n",
      "Writing 1850373 lines to /workspace/datasets/week4/labeled_data.mq1000.txt\n",
      "Writing 50000 lines to /workspace/datasets/week4/train.mq1000.txt\n",
      "Writing 50000 lines to /workspace/datasets/week4/test.mq1000.txt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args='python /workspace/search_with_machine_learning_course/week4/create_labeled_queries.py --min_queries 1000', returncode=0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmd = f\"python /workspace/search_with_machine_learning_course/week4/create_labeled_queries.py --min_queries 1000\"\n",
    "print(f\"+ {cmd}\")\n",
    "subprocess.run(cmd, shell=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_exp(epoch=5, lr=.1, wordNgrams=1):\n",
    "    for mq in [\"100\", \"1000\"]:\n",
    "        model = f\"model.mq{mq}.e{epoch}.lr{lr}.ng{wordNgrams}\"\n",
    "        cmd = f\"fasttext supervised -input train.mq{mq}.txt -output {model} -epoch {epoch} -lr {lr} -wordNgrams {wordNgrams} -seed 42\"\n",
    "        print(\"+\", cmd)\n",
    "        subprocess.run(cmd, shell=True)\n",
    "        subprocess.run(f\"fasttext test {model}.bin test.mq{mq}.txt\", shell=True)\n",
    "        subprocess.run(f\"fasttext test {model}.bin test.mq{mq}.txt 3\", shell=True)\n",
    "        subprocess.run(f\"fasttext test {model}.bin test.mq{mq}.txt 5\", shell=True)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Default fasttext parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ fasttext supervised -input train.mq100.txt -output model.mq100.e5.lr0.1.ng1 -epoch 5 -lr 0.1 -wordNgrams 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read 0M words\n",
      "Number of words:  7640\n",
      "Number of labels: 872\n",
      "Progress: 100.0% words/sec/thread:    7381 lr:  0.000000 avg.loss:  5.311603 ETA:   0h 0m 0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N\t49986\n",
      "P@1\t0.466\n",
      "R@1\t0.466\n",
      "N\t49986\n",
      "P@3\t0.207\n",
      "R@3\t0.62\n",
      "N\t49986\n",
      "P@5\t0.136\n",
      "R@5\t0.678\n",
      "\n",
      "+ fasttext supervised -input train.mq1000.txt -output model.mq1000.e5.lr0.1.ng1 -epoch 5 -lr 0.1 -wordNgrams 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read 0M words\n",
      "Number of words:  7759\n",
      "Number of labels: 387\n",
      "Progress: 100.0% words/sec/thread:   15636 lr:  0.000000 avg.loss:  4.309403 ETA:   0h 0m 0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N\t50000\n",
      "P@1\t0.481\n",
      "R@1\t0.481\n",
      "N\t50000\n",
      "P@3\t0.214\n",
      "R@3\t0.643\n",
      "N\t50000\n",
      "P@5\t0.141\n",
      "R@5\t0.707\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_exp()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Increasing learning rate\n",
    "\n",
    "Increasing learning rate improves precision and recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ fasttext supervised -input train.mq100.txt -output model.mq100.e5.lr0.5.ng1 -epoch 5 -lr 0.5 -wordNgrams 1 -seed 42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read 0M words\n",
      "Number of words:  7640\n",
      "Number of labels: 872\n",
      "Progress: 100.0% words/sec/thread:    7450 lr:  0.000000 avg.loss:  3.887329 ETA:   0h 0m 0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N\t49986\n",
      "P@1\t0.516\n",
      "R@1\t0.516\n",
      "N\t49986\n",
      "P@3\t0.232\n",
      "R@3\t0.697\n",
      "N\t49986\n",
      "P@5\t0.152\n",
      "R@5\t0.762\n",
      "\n",
      "+ fasttext supervised -input train.mq1000.txt -output model.mq1000.e5.lr0.5.ng1 -epoch 5 -lr 0.5 -wordNgrams 1 -seed 42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read 0M words\n",
      "Number of words:  7759\n",
      "Number of labels: 387\n",
      "Progress: 100.0% words/sec/thread:   16268 lr:  0.000000 avg.loss:  3.607438 ETA:   0h 0m 0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N\t50000\n",
      "P@1\t0.525\n",
      "R@1\t0.525\n",
      "N\t50000\n",
      "P@3\t0.236\n",
      "R@3\t0.708\n",
      "N\t50000\n",
      "P@5\t0.154\n",
      "R@5\t0.772\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_exp(lr=.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Increasing epochs\n",
    "\n",
    "Similar improvement as with increased learning rate. Perhaps default parameters result in underfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ fasttext supervised -input train.mq100.txt -output model.mq100.e25.lr0.1.ng1 -epoch 25 -lr 0.1 -wordNgrams 1 -seed 42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read 0M words\n",
      "Number of words:  7640\n",
      "Number of labels: 872\n",
      "Progress: 100.0% words/sec/thread:    7312 lr:  0.000000 avg.loss:  2.566525 ETA:   0h 0m 0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N\t49986\n",
      "P@1\t0.518\n",
      "R@1\t0.518\n",
      "N\t49986\n",
      "P@3\t0.232\n",
      "R@3\t0.697\n",
      "N\t49986\n",
      "P@5\t0.152\n",
      "R@5\t0.761\n",
      "\n",
      "+ fasttext supervised -input train.mq1000.txt -output model.mq1000.e25.lr0.1.ng1 -epoch 25 -lr 0.1 -wordNgrams 1 -seed 42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read 0M words\n",
      "Number of words:  7759\n",
      "Number of labels: 387\n",
      "Progress: 100.0% words/sec/thread:   16006 lr:  0.000000 avg.loss:  2.238065 ETA:   0h 0m 0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N\t50000\n",
      "P@1\t0.526\n",
      "R@1\t0.526\n",
      "N\t50000\n",
      "P@3\t0.236\n",
      "R@3\t0.708\n",
      "N\t50000\n",
      "P@5\t0.154\n",
      "R@5\t0.769\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_exp(epoch=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Increasing both epochs and learning rate\n",
    "\n",
    "Increasing both doesn't really change much."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ fasttext supervised -input train.mq100.txt -output model.mq100.e25.lr0.5.ng1 -epoch 25 -lr 0.5 -wordNgrams 1 -seed 42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read 0M words\n",
      "Number of words:  7640\n",
      "Number of labels: 872\n",
      "Progress: 100.0% words/sec/thread:    7474 lr:  0.000000 avg.loss:  3.262587 ETA:   0h 0m 0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N\t49986\n",
      "P@1\t0.514\n",
      "R@1\t0.514\n",
      "N\t49986\n",
      "P@3\t0.231\n",
      "R@3\t0.692\n",
      "N\t49986\n",
      "P@5\t0.151\n",
      "R@5\t0.753\n",
      "\n",
      "+ fasttext supervised -input train.mq1000.txt -output model.mq1000.e25.lr0.5.ng1 -epoch 25 -lr 0.5 -wordNgrams 1 -seed 42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read 0M words\n",
      "Number of words:  7759\n",
      "Number of labels: 387\n",
      "Progress: 100.0% words/sec/thread:   16461 lr:  0.000000 avg.loss:  2.844285 ETA:   0h 0m 0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N\t50000\n",
      "P@1\t0.522\n",
      "R@1\t0.522\n",
      "N\t50000\n",
      "P@3\t0.235\n",
      "R@3\t0.705\n",
      "N\t50000\n",
      "P@5\t0.153\n",
      "R@5\t0.765\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_exp(epoch=25, lr=.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ fasttext supervised -input train.mq100.txt -output model.mq100.e5.lr0.5.ng2 -epoch 5 -lr 0.5 -wordNgrams 2 -seed 42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read 0M words\n",
      "Number of words:  7640\n",
      "Number of labels: 872\n",
      "Progress: 100.0% words/sec/thread:    7382 lr:  0.000000 avg.loss:  3.655626 ETA:   0h 0m 0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N\t49986\n",
      "P@1\t0.514\n",
      "R@1\t0.514\n",
      "N\t49986\n",
      "P@3\t0.232\n",
      "R@3\t0.696\n",
      "N\t49986\n",
      "P@5\t0.152\n",
      "R@5\t0.762\n",
      "\n",
      "+ fasttext supervised -input train.mq1000.txt -output model.mq1000.e5.lr0.5.ng2 -epoch 5 -lr 0.5 -wordNgrams 2 -seed 42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read 0M words\n",
      "Number of words:  7759\n",
      "Number of labels: 387\n",
      "Progress: 100.0% words/sec/thread:   15927 lr:  0.000000 avg.loss:  3.092229 ETA:   0h 0m 0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N\t50000\n",
      "P@1\t0.527\n",
      "R@1\t0.527\n",
      "N\t50000\n",
      "P@3\t0.237\n",
      "R@3\t0.712\n",
      "N\t50000\n",
      "P@5\t0.155\n",
      "R@5\t0.777\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_exp(lr=.5, wordNgrams=2)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "17f19b2e755769a5519b38b6367878bc0c8e8eee85e91277104d2410a6f820df"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('py39')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
